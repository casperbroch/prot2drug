{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee64893-167d-497f-ba41-75a33e868f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021b363-8cdc-4c56-abe0-a991bd1da377",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137d7a98-822a-433e-9b11-6a05d55d902e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1A. Query data directly from PDB "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a30512d-f8b3-4c62-9d82-b34d610ecac7",
   "metadata": {},
   "source": [
    "**Search query**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885370e1-f493-48b6-8ec6-0142e519e41b",
   "metadata": {},
   "source": [
    "Getting all PDB IDs where the polymer type is \"Protein\" and where a bound ligand exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e7d8b74-1319-403f-a013-59e5918ddc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcsbapi.search import search_attributes as attrs\n",
    "# To see possible attributes, do attrs.__dict__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a4ca1d38-d6c5-4ab3-8797-0cfb24a3525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14866 protein–ligand complexes\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    (attrs.entity_poly.rcsb_entity_polymer_type == \"Protein\") & \n",
    "    (attrs.rcsb_ligand_neighbors.ligand_entity_id.exists()) & \n",
    "    (attrs.rcsb_binding_affinity.value.exists()) \n",
    "    # (attrs.rcsb_nonpolymer_entity.pdbx_number_of_molecules > 0) &\n",
    "    # (attrs.rcsb_binding_affinity.value >= 0) & \n",
    "    # (attrs.rcsb_binding_affinity.value < ...) & \n",
    "    # (attrs.rcsb_nonpolymer_entity.formula_weight > 150) \n",
    ")\n",
    "pdb_ids = list(query())\n",
    "print(len(pdb_ids), \"protein–ligand complexes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038aa1fc-2418-48e7-a06b-6f2dc4eb043e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d512365f-6d74-43ff-8138-94a2f55a652b",
   "metadata": {},
   "source": [
    "**Data query**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51766f09-0185-46b2-9346-785ab458c681",
   "metadata": {},
   "source": [
    "Getting the data for these PDB entries. For now, let's only get the Ligand IDs for now.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3e9b1785-446c-48df-a0a1-3b8e4b2184da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rcsbapi.data import DataQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b1e04b38-6142-43ba-ac2a-8d5a32d57610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10GS', '11GS']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pdb_ids = pdb_ids[:2]\n",
    "test_pdb_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6cbbd86a-88fe-4dcd-8757-288614009065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 protein–ligand complexes\n"
     ]
    }
   ],
   "source": [
    "query = DataQuery(\n",
    "    input_type=\"entries\",\n",
    "    input_ids=test_pdb_ids,\n",
    "    return_data_list=[\n",
    "        \"rcsb_id\",\n",
    "        \"nonpolymer_entities.nonpolymer_comp.chem_comp.id\"\n",
    "    ]\n",
    ")\n",
    "protein_ligand_data = query.exec()\n",
    "print(len(protein_ligand_data[\"data\"][\"entries\"]), \"protein–ligand complexes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9e3d1a0a-6e58-41e5-aa95-0c78dc18692f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rcsb_id': '10GS', 'nonpolymer_entities': [{'nonpolymer_comp': {'chem_comp': {'id': 'VWW'}}}, {'nonpolymer_comp': {'chem_comp': {'id': 'MES'}}}]}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example protein–ligand complex record: \n",
    "protein_ligand_data[\"data\"][\"entries\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9bfc9cb1-bcef-4838-bddf-5bae1e83fe7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average number of ligands per protein–ligand complex: \n",
    "np.mean([\n",
    "    len(record[\"nonpolymer_entities\"]) \n",
    "    for record in protein_ligand_complexes[\"data\"][\"entries\"]\n",
    "])\n",
    "\n",
    "# If most protein–ligand complexes have more than 1 ligand, that could be a problem \n",
    "# as I don't know if our approach can handle this "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ddfa4f-50fb-4f7f-a47b-cca43cd30526",
   "metadata": {},
   "source": [
    "Now that we have the protein–ligand complexes, we still need to fetch data on those ligands, including their SMILES strings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "25aa90f3-6b68-40a1-bbd1-122f2b9a8bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of unique ligand IDs from above protein–ligand data: \n",
    "ligand_ids = list(set(\n",
    "    ligand[\"nonpolymer_comp\"][\"chem_comp\"][\"id\"] \n",
    "    for protein_ligand in protein_ligand_data[\"data\"][\"entries\"] \n",
    "    for ligand in protein_ligand[\"nonpolymer_entities\"]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1b935de9-f342-4900-912c-4fcf13c2b8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VWW', 'GSH']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ligand_ids = ligand_ids[:2]\n",
    "test_ligand_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b9258800-5399-47ac-a543-64c37bb51283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 ligands\n"
     ]
    }
   ],
   "source": [
    "# For attributes, e.g. go to https://www.rcsb.org/ligand/VWW, click \"Data API\", which opens a GraphiQL UI, then run it. \n",
    "\n",
    "query = DataQuery(\n",
    "    input_type=\"chem_comps\",\n",
    "    input_ids=test_ligand_ids,\n",
    "    return_data_list=[\n",
    "        \"chem_comp.id\",\n",
    "        \"chem_comp.type\",\n",
    "        \"chem_comp.name\",\n",
    "        \"chem_comp.formula\",\n",
    "        \"rcsb_chem_comp_descriptor.SMILES\",\n",
    "        # Not sure if these might also come in handy: \n",
    "        \"rcsb_chem_comp_info.atom_count\", \n",
    "        \"rcsb_chem_comp_info.bond_count\", \n",
    "        \"pdbx_chem_comp_identifier\",\n",
    "        \"rcsb_chem_comp_related\",\n",
    "        \"drugbank.drugbank_info.drugbank_id\",\n",
    "        \"drugbank.durgbank_target.name\",\n",
    "        \"drugbank.durgbank_target.interaction_type\",\n",
    "    ]\n",
    ")\n",
    "ligand_data = query.exec()\n",
    "print(len(ligand_data[\"data\"][\"chem_comps\"]), \"ligands\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406cbc79-bebd-4a70-abd4-f0cba722258f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1180c7-3d65-423e-9702-d8568b56f83c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1B. Use Huggingface dataset `pdb_protein_ligand_complexes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9911aac-fc9c-4138-a9d7-70e377605780",
   "metadata": {},
   "source": [
    "Download from here https://huggingface.co/datasets/jglaser/pdb_protein_ligand_complexes  \n",
    "and put in `data/` directory.  \n",
    "I also renamed them to: `pdb_protein_ligand_full_train.p` and `pdb_protein_ligand_full_test.p`  \n",
    "I removed unnecessry columns and saved the new datasets to: `pdb_protein_ligand_train.p` and `pdb_protein_ligand_test.p`  \n",
    "which are much smaller. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b2c3005-1347-411c-a17d-a9ab2d435bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd4f11d9-36b9-448d-bac0-c46b313482a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein_ligand_train = pd.read_pickle(\"data/pdb_protein_ligand_full_train.p\")\n",
    "# protein_ligand_train[[\"pdb_id\", \"lig_id\", \"seq\", \"smiles\"]].to_pickle(\"data/pdb_protein_ligand_train.p\")\n",
    "protein_ligand_train = pd.read_pickle(\"data/pdb_protein_ligand_train.p\")\n",
    "\n",
    "# protein_ligand_test = pd.read_pickle(\"data/pdb_protein_ligand_full_test.p\")\n",
    "# protein_ligand_test[[\"pdb_id\", \"lig_id\", \"seq\", \"smiles\"]].to_pickle(\"data/pdb_protein_ligand_test.p\")\n",
    "protein_ligand_test = pd.read_pickle(\"data/pdb_protein_ligand_test.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eea48470-d587-499a-8cd6-6879ac810cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pdb_id</th>\n",
       "      <th>lig_id</th>\n",
       "      <th>seq</th>\n",
       "      <th>smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7k38</td>\n",
       "      <td>VTY</td>\n",
       "      <td>MGIVEEAHNVKVLGTGSRFIVLAHGFGTDQSVWKHLVPHLLEEFRV...</td>\n",
       "      <td>CC1=C[C@@H](O)OC1=O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6prt</td>\n",
       "      <td>OWA</td>\n",
       "      <td>SNPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVD...</td>\n",
       "      <td>COC(=O)C[C@H]1CC(=O)N(C)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4lxx</td>\n",
       "      <td>FNF</td>\n",
       "      <td>GHMIKICIAGKNNIAVNSLQFILKNYFEADQIVVIPNKNDKGIDSW...</td>\n",
       "      <td>Cc1cn([C@H]2C[C@H](O)[C@@H](COP(=O)(O)OP(=O)(O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4lxx</td>\n",
       "      <td>FON</td>\n",
       "      <td>GHMIKICIAGKNNIAVNSLQFILKNYFEADQIVVIPNKNDKGIDSW...</td>\n",
       "      <td>Nc1nc(=O)c2c([nH]1)NC[C@@H](CNc1ccc(C(=O)N[C@@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7bp1</td>\n",
       "      <td>CAQ</td>\n",
       "      <td>MLGKVALEEAFALPRHKERTRWWAGLFAIDPDKHAAEINDITEQRI...</td>\n",
       "      <td>Oc1ccccc1O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4ibj</td>\n",
       "      <td>1D9</td>\n",
       "      <td>PDISAKDLRNIMYDHLPGFGTAFHQLVQVICKLGKDSNSLDIIHAE...</td>\n",
       "      <td>O=C(O)c1cccc(N2C(=O)C(O)=C(C(=O)c3cccc(C(F)(F)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1psa</td>\n",
       "      <td>0ZL</td>\n",
       "      <td>IGDEPLENYLDTEYFGTIGIGTPAQDFTVIFDTGSSNLWVPSVYCS...</td>\n",
       "      <td>CCOC(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CC(C)C)C(=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5ag7</td>\n",
       "      <td>XXL</td>\n",
       "      <td>AHAFWSTQPVPQTEDETEKIVFAGPMDEPKTVADIPEEPYPIASTF...</td>\n",
       "      <td>CCOC(=O)CN1C(=O)COc2ccccc21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1kdr</td>\n",
       "      <td>CAR</td>\n",
       "      <td>AIAPVITIDGPSGAGKGTLCKAMAEALQWHLLDSGAIYRVLALAAL...</td>\n",
       "      <td>Nc1ccn([C@@H]2O[C@H](COP(=O)(O)O)[C@@H](O)[C@@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1v0c</td>\n",
       "      <td>KNC</td>\n",
       "      <td>DSVTLRLMTEHDLAMLYEWLNRSHIVEWWGARPTLADVQEQYLPSV...</td>\n",
       "      <td>N[C@H]1[C@H](O)[C@@H](CO)O[C@H](O[C@@H]2[C@@H]...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pdb_id lig_id                                                seq  \\\n",
       "0   7k38    VTY  MGIVEEAHNVKVLGTGSRFIVLAHGFGTDQSVWKHLVPHLLEEFRV...   \n",
       "1   6prt    OWA  SNPPPPETSNPNKPKRQTNQLQYLLRVVLKTLWKHQFAWPFQQPVD...   \n",
       "2   4lxx    FNF  GHMIKICIAGKNNIAVNSLQFILKNYFEADQIVVIPNKNDKGIDSW...   \n",
       "3   4lxx    FON  GHMIKICIAGKNNIAVNSLQFILKNYFEADQIVVIPNKNDKGIDSW...   \n",
       "4   7bp1    CAQ  MLGKVALEEAFALPRHKERTRWWAGLFAIDPDKHAAEINDITEQRI...   \n",
       "5   4ibj    1D9  PDISAKDLRNIMYDHLPGFGTAFHQLVQVICKLGKDSNSLDIIHAE...   \n",
       "6   1psa    0ZL  IGDEPLENYLDTEYFGTIGIGTPAQDFTVIFDTGSSNLWVPSVYCS...   \n",
       "7   5ag7    XXL  AHAFWSTQPVPQTEDETEKIVFAGPMDEPKTVADIPEEPYPIASTF...   \n",
       "8   1kdr    CAR  AIAPVITIDGPSGAGKGTLCKAMAEALQWHLLDSGAIYRVLALAAL...   \n",
       "9   1v0c    KNC  DSVTLRLMTEHDLAMLYEWLNRSHIVEWWGARPTLADVQEQYLPSV...   \n",
       "\n",
       "                                              smiles  \n",
       "0                                CC1=C[C@@H](O)OC1=O  \n",
       "1                         COC(=O)C[C@H]1CC(=O)N(C)C1  \n",
       "2  Cc1cn([C@H]2C[C@H](O)[C@@H](COP(=O)(O)OP(=O)(O...  \n",
       "3  Nc1nc(=O)c2c([nH]1)NC[C@@H](CNc1ccc(C(=O)N[C@@...  \n",
       "4                                         Oc1ccccc1O  \n",
       "5  O=C(O)c1cccc(N2C(=O)C(O)=C(C(=O)c3cccc(C(F)(F)...  \n",
       "6  CCOC(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CC(C)C)C(=...  \n",
       "7                        CCOC(=O)CN1C(=O)COc2ccccc21  \n",
       "8  Nc1ccn([C@@H]2O[C@H](COP(=O)(O)O)[C@@H](O)[C@@...  \n",
       "9  N[C@H]1[C@H](O)[C@@H](CO)O[C@H](O[C@@H]2[C@@H]...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein_ligand_test.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842fb151-7aa1-4539-9575-f42a8b94d765",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a7843d-26a5-4932-a2e3-5bda860cc246",
   "metadata": {},
   "source": [
    "### 2. Apply SynFormer to the SMILES strings to generate the dataset of synthesis tokens "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb9e21-a160-449c-a3e4-2842784c035f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">  \n",
    "Unfortunately, this code doesn't work for me if I simply install/import <b>synformer</b><br/>\n",
    "Instead, I cloned the repo (https://github.com/wenhao-gao/synformer) and put this notebook in there<br/>\n",
    "Then in the virtual environment, I did \"pip install -e .\" to install the local version<br/>\n",
    "I also had to fix something in that local version:<br/>\n",
    "In synformer/sampler/analog/cli.py, line 4, change<br/> \n",
    "<pre style=\"background-color:lightgray\">\n",
    "from parallel import run_parallel_sampling\n",
    "</pre>\n",
    "to this:<br/>\n",
    "<pre style=\"background-color:lightgray\">\n",
    "from synformer.sampler.analog.parallel import run_parallel_sampling\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eff562-624f-482c-bf9c-2d0a797ff1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want a dataset (lig_id, original_smiles, projected_smiles), and then possibly multiple projections \n",
    "# per lig_id entry, so (lig_id, original_smiles, projected_smiles, projection_id) \n",
    "# But besides the SMILES, we need all 3 outputs from SynFormer: token type, reaction token, reactant token \n",
    "# If I remember correctly, there is a vocabulary of reaction tokens, so it would be enough to store the reaction token IDs,\n",
    "# which we can look up in the \n",
    "# I'm not sure if we can do the same with the reactants, as there is no vocabulary. But from the ID, perhaps we can\n",
    "# get the fingerprint and then at will we can pass it through the embedding layer to get the embedding vector \n",
    "# Because if we store the entire embedding vector for each reactant in all examples, that dataset would be unnecessarily big\n",
    "# Ideally, we just keep the IDs \n",
    "# We want the ground-truth embeddings anyway, not the predicted embeddings which would then be Nearest-Neighbor'ed to the ground truth embedding \n",
    "# So now the dataset would look like this: \n",
    "\n",
    "# (lig_id, original_smiles, projected_smiles, projection_id, token_types_tensor, reactions_tensor, reactants_tensor) \n",
    "\n",
    "# the tensors all seem to have a fixed sequence length of 24 \n",
    "# I could also simply store all non-END and non-START tokens, and then during the prediction I prepend/append them, as they're always the same \n",
    "\n",
    "# optionally, I could also store the similarity score between the original and projected molecules "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc61ab7-9bed-4270-b612-cf2dc55d72d9",
   "metadata": {},
   "source": [
    "The following code is partly based on `scripts/sample_naive.py` form the Synformer repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7e92a7-68a9-4949-8dea-16cc78563e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports from scripts/sample_naive.py: \n",
    "import pathlib\n",
    "import pickle\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from synformer.chem.fpindex import FingerprintIndex\n",
    "from synformer.chem.matrix import ReactantReactionMatrix\n",
    "from synformer.chem.mol import Molecule\n",
    "from synformer.models.synformer import Synformer\n",
    "\n",
    "# My own imports:\n",
    "import pandas as pd \n",
    "from scripts.sample_naive import sample_naive, load_model, featurize_smiles \n",
    "# from synformer.models.synformer import draw_generation_results\n",
    "from synformer.data.common import TokenType\n",
    "from datetime import datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bb887-2fe3-47b4-82cf-aa96d3b42a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"data/trained_weights/sf_ed_default.ckpt\"\n",
    "CONFIG_PATH = None \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3fa08-2c5c-4929-913e-e21d61a7a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, fpindex, rxn_matrix = load_model(MODEL_PATH, CONFIG_PATH, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1e5a4-779c-49ff-83bc-0bcfad94163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synthetic_pathway(smiles, lig_id=None, repeat=1):\n",
    "    data = []\n",
    "    mol, feat = featurize_smiles(smiles, DEVICE, repeat=repeat)\n",
    "    with torch.inference_mode():wa\n",
    "        result = model.generate_without_stack(\n",
    "            feat,\n",
    "            rxn_matrix=rxn_matrix,\n",
    "            fpindex=fpindex,\n",
    "            temperature_token=1.0,\n",
    "            temperature_reactant=0.1,\n",
    "            temperature_reaction=1.0,\n",
    "        )\n",
    "        ll = model.get_log_likelihood(\n",
    "            code=result.code,\n",
    "            code_padding_mask=result.code_padding_mask,\n",
    "            token_types=result.token_types,\n",
    "            rxn_indices=result.rxn_indices,\n",
    "            reactant_fps=result.reactant_fps,\n",
    "            token_padding_mask=result.token_padding_mask,\n",
    "        )\n",
    "    stacks = result.build() \n",
    "    for i, stack in enumerate(stacks):\n",
    "        # Only those sequences with stack depth of 1 (i.e. applying the building blocks and reactions leads to 1 final molecule) \n",
    "        # are considered valid results!! \n",
    "        if stack.get_stack_depth() == 1:\n",
    "            analog_mol = stack.get_one_top()\n",
    "            sim = analog_mol.sim(mol)\n",
    "            # TODO: perhaps only continue if similarity score sufficiently high? \n",
    "            token_types = result.token_types[i]\n",
    "            # Location of first END token (we only need to store tokens up until this point): \n",
    "            end_id = token_types.tolist().index(0)\n",
    "            token_types = token_types[:end_id].tolist()\n",
    "            rxn_indices = result.rxn_indices[i,:end_id].tolist()\n",
    "            reactant_indices = result.reactant_indices[i,:end_id].tolist()\n",
    "            data.append([\n",
    "                lig_id,\n",
    "                smiles, \n",
    "                analog_mol.smiles, \n",
    "                round(sim, 4), \n",
    "                token_types,\n",
    "                rxn_indices,\n",
    "                reactant_indices\n",
    "            ])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae64e5f-7040-4c58-bd43-692cdd19cd97",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0487a0d7-8822-4eb8-bb9f-ccad68710d4f",
   "metadata": {},
   "source": [
    "Apply to dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ca93528-0499-4a0d-8ed6-dbff62aa8996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21096, 2)\n",
      "(3148, 2)\n"
     ]
    }
   ],
   "source": [
    "protein_ligand_train = pd.read_pickle(\"data/pdb_protein_ligand_train.p\")\n",
    "ligands_train = protein_ligand_train[[\"lig_id\", \"smiles\"]].drop_duplicates()\n",
    "del protein_ligand_train\n",
    "print(ligands_train.shape)\n",
    "\n",
    "protein_ligand_test = pd.read_pickle(\"data/pdb_protein_ligand_test.p\")\n",
    "ligands_test = protein_ligand_test[[\"lig_id\", \"smiles\"]].drop_duplicates()\n",
    "del protein_ligand_test\n",
    "print(ligands_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6058f-274a-4f37-b1ab-186c76b4cd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "data = {}\n",
    "repeat = 1\n",
    "\n",
    "# for ligands, dataset_name in [(ligands_test, \"test\"), (ligands_train, \"train\")]:\n",
    "ligands = ligands_test\n",
    "dataset_name = \"test\" \n",
    "data[dataset_name] = []\n",
    "\n",
    "for i, row in ligands.iterrows():\n",
    "    try:\n",
    "        lig_id = row[\"lig_id\"].item() \n",
    "        smiles = row[\"smiles\"]\n",
    "        print(i, lig_id, smiles)\n",
    "        records = get_synthetic_pathway(smiles, lig_id=lig_id, repeat=repeat)\n",
    "        for record in records:\n",
    "            if record not in data[dataset_name]:\n",
    "                data[dataset_name].append(record)\n",
    "    except Exception as e:\n",
    "        # raise e \n",
    "        print(f\"Error processing SMILES {i} ({e})\")\n",
    "pickle.dump(\n",
    "    data[dataset_name], \n",
    "    open(f\"data/synformer_ligands_{dataset_name}_{datetime.now().strftime('%Y-%m-%d %H-%M-%S')}.pkl\", \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19300a20-7663-4744-8100-2b6b8bf6676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"lig_id\", \"smiles_original\", \"smiles_proj\", \"similarity\", \"token_types\", \"rxn_indices\", \"reactant_indices\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526d695-2b0f-484e-8fa0-ce8a27d0f71e",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91e8fa6-889f-4dfd-b23e-47845701e290",
   "metadata": {},
   "source": [
    "Just for convenience: reconstructing the sequence of building blocks and reactions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64847e7c-1cbb-4d42-b9df-ef47701dfe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_pathway(token_types, rxn_indices, reactant_indices):\n",
    "    \"\"\"\n",
    "    From a list of token types, reaction indices and reactant indices, construct the synthetic pathway\n",
    "    E.g. [1, 3], [0, 99], [0, 10]\n",
    "         This would be mapped to [START, B10, END]\n",
    "         At seq index 0, we have token type 1, which corresponds to the START token, so that's the first token \n",
    "         At seq index 1, we have token type 3, which corresponds to a REACTANT token, which we fetch from reactant_indices\n",
    "                         and in this case is token ID 10, so the token is \"B10\"\n",
    "         That's all of them. \n",
    "         At the end, I append an END token.\n",
    "    Token types:\n",
    "      0: END token (also used for padding, following the actual END token) \n",
    "      1: START token \n",
    "      2: REACTION\n",
    "      3: REACTANT\n",
    "    \"\"\"\n",
    "    pathway = []\n",
    "    for i, token_type in enumerate(token_types):\n",
    "        match token_type:\n",
    "            case 1:\n",
    "                token = \"START\"\n",
    "            case 2:\n",
    "                token = f\"R{rxn_indices[i]}\"\n",
    "            case 3:\n",
    "                token = f\"B{reactant_indices[i]}\"\n",
    "            case _:\n",
    "                token = None \n",
    "        pathway.append(token)\n",
    "    pathway.append(\"END\")\n",
    "    return pathway\n",
    "\n",
    "reconstruct_pathway([1, 3], [0, 85], [-1, 32101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e450a79e-1af8-40fd-9347-2cc7f2daebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df.iloc[:10].iterrows():\n",
    "    print(reconstruct_pathway(row[\"token_types\"], row[\"rxn_indices\"], row[\"reactant_indices\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
